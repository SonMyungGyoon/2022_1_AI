{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"P04_1_2_var_logistic.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"EN2fKMlT8ovP","executionInfo":{"status":"ok","timestamp":1653898561932,"user_tz":-540,"elapsed":8,"user":{"displayName":"손명균","userId":"03357044560778548653"}}},"source":["import numpy as np\n","\n","def sigmoid(x):\n","    return 1 / (1+np.exp(-x))\n","\n","def cross_entropy(t, y):    # 크로스 엔트로피 함수\n","    delta = 1e-7        # log함수의 -무한대 발산 방지\n","    return -np.sum(t*np.log(y + delta) + (1-t)*np.log((1 - y)+delta))\n","\n","def errFunc(x, t):\n","    z = np.dot(x,W) + b     # 선형회귀\n","    y = sigmoid(z)\n","    return cross_entropy(t, y)\n","\n","def errValue(x, t):\n","    return  errFunc(x, t)  \n","\n","def numerical_derivative(f, x):\n","    delta_x = 1e-4 # 0.0001\n","    grad = np.zeros_like(x)\n","            \n","    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n","    while not it.finished:\n","        idx = it.multi_index        \n","        temp = x[idx]\n","        x[idx] = temp + delta_x\n","        fx1 = f(x)  # f(x+delta_x)\n","        \n","        x[idx] = temp - delta_x \n","        fx2 = f(x)  # f(x-delta_x)\n","        grad[idx] = (fx1 - fx2) / (2*delta_x)\n","        \n","        x[idx] = temp \n","        it.iternext()   \n","    return grad\n","\n","def predict(x):\n","    z = np.dot(x,W) + b\n","    y = sigmoid(z)\n","    if y > 0.5:\n","        result = 1  # True\n","    else:\n","        result = 0  # False\n","    return y, result\n","\n","def grad_descent(x_data, t_data, W, b, learning_rate, repeat, outStep):\n","    f = lambda x : errFunc(x_data,t_data)   # errFunc()함수를 다른 함수의 인자로 넘기기 위해 \n","\n","    print(\"Initial error value = {:.3f}\".format(errValue(x_data, t_data)))\n","    print(\"Initial W = \", W.reshape(1,-1).round(3))\n","    print(\"Initial b = \", b.round(3))\n","    for step in range(repeat+1):        # 적당한 횟수만큼 경사하강 반복\n","        W -= learning_rate * numerical_derivative(f, W)\n","        b -= learning_rate * numerical_derivative(f, b)\n","        \n","        if (step % outStep == 0):       # 경사하강 반복 중간마다 손실값 출력\n","            print(\"Step = {:<5d}\".format(step), \"Error Value = {:.4f}\".format(errValue(x_data, t_data)),\n","                  \"W =\", W.reshape(1,-1).round(3), \" b = \", b.round(3))"],"execution_count":1,"outputs":[]},{"cell_type":"code","source":["x_data = np.array([2, 4, 6, 8, 10, 12, 14, 16, 18, 20]).reshape(10, 1)\n","t_data = np.array([0, 0, 0, 0,  0,  0,  1,  1,  1,  1]).reshape(10, 1)\n","W = np.random.rand(1, 1)  # 1X1 행렬\n","b = np.random.rand(1)  \n","learning_rate = 1e-2  # 0.1, 0.01, 0.05, 0.001 일 때의 손실함수 값 비교\n","repeat = 10000\n","outStep = 1000\n","\n","grad_descent(x_data, t_data, W, b, learning_rate, repeat, outStep)\n","predict(13)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L_uHDBdFleDJ","executionInfo":{"status":"ok","timestamp":1653898564107,"user_tz":-540,"elapsed":2181,"user":{"displayName":"손명균","userId":"03357044560778548653"}},"outputId":"8e4dbe0e-08eb-4bd6-f22f-2b236b8a9820"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Initial error value = 43.382\n","Initial W =  [[0.962]]\n","Initial b =  [0.479]\n","Step = 0     Error Value = 25.8140 W = [[0.547]]  b =  [0.422]\n","Step = 1000  Error Value = 1.6236 W = [[0.497]]  b =  [-6.227]\n","Step = 2000  Error Value = 1.2325 W = [[0.645]]  b =  [-8.189]\n","Step = 3000  Error Value = 1.0457 W = [[0.748]]  b =  [-9.552]\n","Step = 4000  Error Value = 0.9285 W = [[0.83]]  b =  [-10.633]\n","Step = 5000  Error Value = 0.8452 W = [[0.9]]  b =  [-11.545]\n","Step = 6000  Error Value = 0.7815 W = [[0.96]]  b =  [-12.343]\n","Step = 7000  Error Value = 0.7304 W = [[1.015]]  b =  [-13.057]\n","Step = 8000  Error Value = 0.6881 W = [[1.065]]  b =  [-13.707]\n","Step = 9000  Error Value = 0.6521 W = [[1.11]]  b =  [-14.306]\n","Step = 10000 Error Value = 0.6210 W = [[1.153]]  b =  [-14.864]\n"]},{"output_type":"execute_result","data":{"text/plain":["(array([[0.5310886]]), 1)"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["predict(33)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lXU8UZTaP-jC","executionInfo":{"status":"ok","timestamp":1653898570094,"user_tz":-540,"elapsed":368,"user":{"displayName":"손명균","userId":"03357044560778548653"}},"outputId":"3087a19e-d06d-4af4-b7de-15c57e1495a9"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([[1.]]), 1)"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["x_data = np.array([ [2, 4], [4, 11], [6, 6], [8, 5], [10, 7], [12, 16], [14, 8], [16, 3], [18, 7] ])\n","t_data = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1]).reshape(9, 1)\n","W = np.random.rand(2, 1)  # 2X1 행렬\n","b = np.random.rand(1)  \n","\n","learning_rate = 1e-2  # 0.1, 0.01, 0.05, 0.001 일 때의 손실함수 값 비교\n","repeat = 80000\n","outStep = 2000\n","\n","grad_descent(x_data, t_data, W, b, learning_rate, repeat, outStep)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VRbk6q69iJrs","executionInfo":{"status":"ok","timestamp":1653466394229,"user_tz":-540,"elapsed":17161,"user":{"displayName":"박창현","userId":"11319827918069864966"}},"outputId":"65281714-a511-4ec4-9aeb-fba282f96e0c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Initial error value = 36.241\n","Initial W =  [[0.755 0.673]]\n","Initial b =  [0.917]\n","Step = 0     Error Value = 25.4084 W = [[0.555 0.414]]  b =  [0.877]\n","Step = 2000  Error Value = 0.9837 W = [[0.749 0.053]]  b =  [-6.877]\n","Step = 4000  Error Value = 0.6838 W = [[0.959 0.127]]  b =  [-9.293]\n","Step = 6000  Error Value = 0.5492 W = [[1.096 0.191]]  b =  [-10.925]\n","Step = 8000  Error Value = 0.4652 W = [[1.197 0.253]]  b =  [-12.216]\n","Step = 10000 Error Value = 0.4053 W = [[1.279 0.312]]  b =  [-13.307]\n","Step = 12000 Error Value = 0.3595 W = [[1.349 0.366]]  b =  [-14.261]\n","Step = 14000 Error Value = 0.3231 W = [[1.411 0.415]]  b =  [-15.111]\n","Step = 16000 Error Value = 0.2934 W = [[1.467 0.459]]  b =  [-15.879]\n","Step = 18000 Error Value = 0.2687 W = [[1.518 0.5  ]]  b =  [-16.58]\n","Step = 20000 Error Value = 0.2477 W = [[1.565 0.537]]  b =  [-17.225]\n","Step = 22000 Error Value = 0.2298 W = [[1.608 0.571]]  b =  [-17.822]\n","Step = 24000 Error Value = 0.2142 W = [[1.649 0.602]]  b =  [-18.378]\n","Step = 26000 Error Value = 0.2006 W = [[1.688 0.632]]  b =  [-18.898]\n","Step = 28000 Error Value = 0.1886 W = [[1.724 0.659]]  b =  [-19.386]\n","Step = 30000 Error Value = 0.1779 W = [[1.758 0.685]]  b =  [-19.846]\n","Step = 32000 Error Value = 0.1684 W = [[1.79  0.709]]  b =  [-20.282]\n","Step = 34000 Error Value = 0.1598 W = [[1.821 0.732]]  b =  [-20.694]\n","Step = 36000 Error Value = 0.1520 W = [[1.85  0.753]]  b =  [-21.087]\n","Step = 38000 Error Value = 0.1450 W = [[1.878 0.774]]  b =  [-21.461]\n","Step = 40000 Error Value = 0.1386 W = [[1.905 0.793]]  b =  [-21.818]\n","Step = 42000 Error Value = 0.1327 W = [[1.93  0.812]]  b =  [-22.16]\n","Step = 44000 Error Value = 0.1272 W = [[1.955 0.83 ]]  b =  [-22.488]\n","Step = 46000 Error Value = 0.1223 W = [[1.978 0.847]]  b =  [-22.803]\n","Step = 48000 Error Value = 0.1176 W = [[2.001 0.863]]  b =  [-23.106]\n","Step = 50000 Error Value = 0.1133 W = [[2.023 0.879]]  b =  [-23.398]\n","Step = 52000 Error Value = 0.1094 W = [[2.044 0.894]]  b =  [-23.679]\n","Step = 54000 Error Value = 0.1056 W = [[2.064 0.909]]  b =  [-23.951]\n","Step = 56000 Error Value = 0.1022 W = [[2.084 0.923]]  b =  [-24.213]\n","Step = 58000 Error Value = 0.0989 W = [[2.103 0.937]]  b =  [-24.468]\n","Step = 60000 Error Value = 0.0958 W = [[2.122 0.95 ]]  b =  [-24.714]\n","Step = 62000 Error Value = 0.0930 W = [[2.14  0.963]]  b =  [-24.953]\n","Step = 64000 Error Value = 0.0903 W = [[2.158 0.975]]  b =  [-25.185]\n","Step = 66000 Error Value = 0.0877 W = [[2.175 0.987]]  b =  [-25.41]\n","Step = 68000 Error Value = 0.0853 W = [[2.191 0.999]]  b =  [-25.629]\n","Step = 70000 Error Value = 0.0830 W = [[2.207 1.01 ]]  b =  [-25.842]\n","Step = 72000 Error Value = 0.0808 W = [[2.223 1.021]]  b =  [-26.049]\n","Step = 74000 Error Value = 0.0788 W = [[2.238 1.032]]  b =  [-26.252]\n","Step = 76000 Error Value = 0.0768 W = [[2.253 1.043]]  b =  [-26.449]\n","Step = 78000 Error Value = 0.0750 W = [[2.268 1.053]]  b =  [-26.641]\n","Step = 80000 Error Value = 0.0732 W = [[2.282 1.063]]  b =  [-26.829]\n"]}]},{"cell_type":"code","metadata":{"id":"GzBubtRNb0Tk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653466404291,"user_tz":-540,"elapsed":402,"user":{"displayName":"박창현","userId":"11319827918069864966"}},"outputId":"3d23deb1-6caa-4d12-c1e9-a9ccd0de7a66"},"source":["test_data = np.array([3, 17]) # (예습, 복습) = (3, 17) => Fail (0)\n","predict(test_data)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([0.12862519]), 0)"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"aRWUU8Hw-YXd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653466406353,"user_tz":-540,"elapsed":365,"user":{"displayName":"박창현","userId":"11319827918069864966"}},"outputId":"8c063cda-b770-46ff-9e06-6b2cacc23f76"},"source":["test_data = np.array([5, 8]) # (예습, 복습) = (5, 8) => Fail (0)\n","predict(test_data)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([0.00099104]), 0)"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"zopxDF7PcRpw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653466413594,"user_tz":-540,"elapsed":384,"user":{"displayName":"박창현","userId":"11319827918069864966"}},"outputId":"be7aa205-3538-40eb-95b0-a17112d0891a"},"source":["test_data = np.array([7, 21]) # (예습, 복습) = (7, 21) => Pass (1)\n","predict(test_data)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([0.99998952]), 1)"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"68xheLdS9cC5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1653466566932,"user_tz":-540,"elapsed":466,"user":{"displayName":"박창현","userId":"11319827918069864966"}},"outputId":"a8d444ee-cd1d-4bb0-e836-c4af8fa985e4"},"source":["test_data = np.array([12, 0])  # (예습, 복습) = (12, 0) => Pass (1)\n","predict(test_data)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([0.63507501]), 1)"]},"metadata":{},"execution_count":11}]}]}